{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((('a', 'VERB'), ('Il', 'PRON')), 7),\n",
       " ((('peut', 'VERB'), ('on', 'PRON')), 4),\n",
       " ((('a', 'VERB'), ('il', 'PRON')), 4),\n",
       " ((('contrôle', 'VERB'), ('il', 'PRON')), 3),\n",
       " ((('faut', 'VERB'), ('il', 'PRON')), 3),\n",
       " ((('est', 'VERB'), (\"c'\", 'PRON')), 3),\n",
       " ((('écrit', 'VERB'), ('Il', 'PRON')), 2),\n",
       " ((('temps', 'NOUN'), ('il', 'PRON')), 2),\n",
       " ((('avez', 'VERB'), ('vous', 'PRON')), 2),\n",
       " ((('va', 'VERB'), ('il', 'PRON')), 2),\n",
       " ((('font', 'VERB'), ('qui', 'PRON')), 2),\n",
       " ((('vois', 'VERB'), ('je', 'PRON')), 2),\n",
       " ((('agit', 'VERB'), ('Il', 'PRON')), 2),\n",
       " ((('visibles', 'ADJ'), ('papillons', 'NOUN')), 2),\n",
       " ((('guette', 'VERB'), ('elle', 'PRON')), 2),\n",
       " ((('vais', 'VERB'), ('je', 'PRON')), 2),\n",
       " ((('faut', 'VERB'), ('Il', 'PRON')), 2),\n",
       " ((('passe', 'VERB'), ('qui', 'PRON')), 1),\n",
       " ((('signifie', 'VERB'), ('RADSL', 'NOUN')), 1),\n",
       " ((('senti', 'VERB'), (\"J'\", 'PRON')), 1),\n",
       " ((('recommande', 'VERB'), ('Je', 'PRON')), 1),\n",
       " ((('abordables', 'ADJ'), ('prix', 'NOUN')), 1),\n",
       " ((('déroule', 'VERB'), ('stage', 'NOUN')), 1),\n",
       " ((('entreprise', 'NOUN'), ('Anjou', 'PROPN')), 1),\n",
       " ((('coupable', 'NOUN'), ('qui', 'PRON')), 1),\n",
       " ((('soit', 'VERB'), ('ce', 'PRON')), 1),\n",
       " ((('est', 'VERB'), ('essentiel', 'NOUN')), 1),\n",
       " ((('trouvé', 'VERB'), ('discours', 'NOUN')), 1),\n",
       " ((('agréables', 'ADJ'), ('chambres', 'NOUN')), 1),\n",
       " ((('dégage', 'VERB'), ('qui', 'PRON')), 1),\n",
       " ((('sérieuse', 'ADJ'), ('école', 'NOUN')), 1),\n",
       " ((('décidé', 'VERB'), ('directrice', 'NOUN')), 1),\n",
       " ((('louvoie', 'VERB'), ('candidate', 'NOUN')), 1),\n",
       " ((('prennent', 'VERB'), ('ils', 'PRON')), 1),\n",
       " ((('étaient', 'VERB'), ('poussière', 'NOUN')), 1),\n",
       " ((('ensemble', 'NOUN'), ('Concert', 'PROPN')), 1),\n",
       " ((('ont', 'VERB'), ('qui', 'PRON')), 1),\n",
       " ((('saura', 'VERB'), ('on', 'PRON')), 1),\n",
       " ((('soi', 'PRON'), ('qui', 'PRON')), 1),\n",
       " ((('peut', 'VERB'), ('On', 'PRON')), 1),\n",
       " ((('apprend', 'VERB'), ('on', 'PRON')), 1),\n",
       " ((('adopté', 'VERB'), ('États', 'NOUN')), 1),\n",
       " ((('aura', 'VERB'), ('on', 'PRON')), 1),\n",
       " ((('massive', 'ADJ'), ('attaque', 'NOUN')), 1),\n",
       " ((('dise', 'VERB'), ('on', 'PRON')), 1),\n",
       " ((('dirigeants', 'NOUN'), ('ce', 'PRON')), 1),\n",
       " ((('disponibles', 'ADJ'), ('épisodes', 'NOUN')), 1),\n",
       " ((('fait', 'VERB'), (\"j'\", 'PRON')), 1),\n",
       " ((('passe', 'VERB'), ('on', 'PRON')), 1),\n",
       " ((('organisée', 'VERB'), ('réunion', 'NOUN')), 1),\n",
       " ((('évadés', 'VERB'), ('qui', 'PRON')), 1),\n",
       " ((('bénéficiant', 'VERB'), ('Rabat', 'PROPN')), 1),\n",
       " ((('bons', 'ADJ'), ('plats', 'NOUN')), 1),\n",
       " ((('claire', 'ADJ'), ('question', 'NOUN')), 1),\n",
       " ((('atteint', 'VERB'), ('excédent', 'NOUN')), 1),\n",
       " ((('va', 'VERB'), ('fils', 'NOUN')), 1),\n",
       " ((('va', 'VERB'), ('ministre', 'NOUN')), 1),\n",
       " ((('dit', 'VERB'), ('Eglise', 'PROPN')), 1),\n",
       " ((('veulent', 'VERB'), ('qui', 'PRON')), 1),\n",
       " ((('marquent', 'VERB'), ('attributs', 'NOUN')), 1),\n",
       " ((('parvient', 'VERB'), ('prédicateur', 'NOUN')), 1),\n",
       " ((('éprouve', 'VERB'), ('président', 'NOUN')), 1),\n",
       " ((('rassurant', 'ADJ'), (\"c'\", 'PRON')), 1),\n",
       " ((('pointe', 'VERB'), ('aide', 'NOUN')), 1),\n",
       " ((('directeur', 'NOUN'), ('Il', 'PRON')), 1),\n",
       " ((('doivent', 'VERB'), ('différence', 'NOUN')), 1),\n",
       " ((('constitue', 'VERB'), ('réorientation', 'NOUN')), 1),\n",
       " ((('favori', 'ADJ'), ('Inter', 'PROPN')), 1),\n",
       " ((('vu', 'VERB'), ('qui', 'PRON')), 1),\n",
       " ((('vouée', 'VERB'), ('voie', 'NOUN')), 1),\n",
       " ((('caillou', 'NOUN'), (\"C'\", 'PRON')), 1),\n",
       " ((('affirmé', 'VERB'), ('il', 'PRON')), 1),\n",
       " ((('inutile', 'ADJ'), ('approche', 'NOUN')), 1),\n",
       " ((('allé', 'VERB'), (\"J'\", 'PRON')), 1),\n",
       " ((('rapportera', 'VERB'), ('épargne', 'NOUN')), 1),\n",
       " ((('levé', 'VERB'), ('Sean', 'PROPN')), 1),\n",
       " ((('pouvait', 'VERB'), ('il', 'PRON')), 1),\n",
       " ((('capot', 'NOUN'), ('Elle', 'PRON')), 1),\n",
       " ((('créent', 'VERB'), ('fonctionnement', 'NOUN')), 1),\n",
       " ((('éclatera', 'VERB'), ('on', 'PRON')), 1),\n",
       " ((('quête', 'NOUN'), ('DGSE', 'PROPN')), 1),\n",
       " ((('vend', 'VERB'), ('qui', 'PRON')), 1),\n",
       " ((('ressent', 'VERB'), ('elle', 'PRON')), 1),\n",
       " ((('vaut', 'VERB'), ('qui', 'PRON')), 1),\n",
       " ((('dirais', 'VERB'), ('je', 'PRON')), 1),\n",
       " ((('ouverts', 'ADJ'), ('Tchèques', 'PROPN')), 1),\n",
       " ((('voit', 'VERB'), ('on', 'PRON')), 1),\n",
       " ((('place', 'VERB'), ('Personne', 'PRON')), 1),\n",
       " ((('utilisent', 'VERB'), ('%', 'SYM')), 1),\n",
       " ((('retourne', 'VERB'), ('on', 'PRON')), 1),\n",
       " ((('simple', 'ADJ'), (\"C'\", 'PRON')), 1),\n",
       " ((('GAME', 'NOUN'), ('Battlefield', 'PROPN')), 1),\n",
       " ((('h', 'NOUN'), ('Il', 'PRON')), 1),\n",
       " ((('ramené', 'VERB'), ('chef', 'NOUN')), 1),\n",
       " ((('cherche', 'VERB'), ('agent', 'NOUN')), 1),\n",
       " ((('installé', 'VERB'), (\"J'\", 'PRON')), 1),\n",
       " ((('évolué', 'VERB'), ('position', 'NOUN')), 1),\n",
       " ((('excellent', 'ADJ'), ('ils', 'PRON')), 1),\n",
       " ((('dis', 'VERB'), ('je', 'PRON')), 1),\n",
       " ((('ferment', 'VERB'), ('terrains', 'NOUN')), 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse import (\n",
    "     DependencyGraph,\n",
    "     ProjectiveDependencyParser,\n",
    "     NonprojectiveDependencyParser,\n",
    " )\n",
    "from nltk import FreqDist\n",
    "\n",
    "root = \"../\"\n",
    "train = \"fr-ud-train.conllu3\"\n",
    "test = \"fr-ud-test.conllu3\"\n",
    "COLUMN_TYPES = ('ignore', \n",
    "                'words', \n",
    "                'ignore', \n",
    "                'pos', \n",
    "                'ignore', \n",
    "                'ignore', \n",
    "                'ignore', \n",
    "                'ignore', \n",
    "                'ignore', \n",
    "                'ignore')\n",
    "\n",
    "trainCorpus  = ConllCorpusReader(root=root, \n",
    "                                  fileids=train, \n",
    "                                  columntypes=COLUMN_TYPES, \n",
    "                                  encoding='utf8', \n",
    "                                  separator=\"\\t\", \n",
    "                                  tagset='universal')\n",
    "\n",
    "testCorpus  = ConllCorpusReader(root=root, \n",
    "                                  fileids=test, \n",
    "                                  columntypes=COLUMN_TYPES, \n",
    "                                  encoding='utf8', \n",
    "                                  separator=\"\\t\", \n",
    "                                  tagset='universal')\n",
    "\n",
    "#trainWords = trainCorpus.tagged_sents()\n",
    "testWords = testCorpus.tagged_sents()\n",
    "#print(trainWords)\n",
    "\n",
    "myfile = open(\"../fr-ud-test.conllu3\")\n",
    "conllfile = myfile.read()\n",
    "ff = conllfile.split('\\n\\n')\n",
    "\n",
    "dg = []\n",
    "for f in ff[:-1]:\n",
    "    #print(f)\n",
    "    dg.append(DependencyGraph(f, cell_separator='\\t', top_relation_label='root'))\n",
    "\n",
    "triplets = []\n",
    "for graph in dg:\n",
    "    for head, rel, dep in graph.triples():\n",
    "        if(rel == 'nsubj'):\n",
    "            triplets.append((head, dep))\n",
    "print(len(triplets))\n",
    "fdist = FreqDist(triplets)\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
