{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('sens', 'VERB'), 'nsubj', ('Je', 'PRON')), 417),\n",
       " ((('vus', 'VERB'), 'aux', ('avons', 'AUX')), 417),\n",
       " ((('pourrions', 'VERB'), 'nsubj', ('nous', 'PRON')), 417),\n",
       " ((('films', 'NOUN'), 'nmod', ('médecins', 'NOUN')), 417),\n",
       " ((('vus', 'VERB'), 'advmod', ('déjà', 'ADV')), 417),\n",
       " ((('ça', 'PRON'), 'conj', ('films', 'NOUN')), 417),\n",
       " ((('scientifiques', 'NOUN'), 'amod', ('fous', 'ADJ')), 417),\n",
       " ((('chemin', 'NOUN'), 'det', ('un', 'DET')), 417),\n",
       " ((('vus', 'VERB'), 'nsubj', ('nous', 'PRON')), 417),\n",
       " ((('emprunter', 'VERB'), 'obl', ('origine', 'NOUN')), 417),\n",
       " ((('pourrions', 'VERB'), 'mark', (\"qu'\", 'SCONJ')), 417),\n",
       " ((('origine', 'NOUN'), 'case', ('pour', 'ADP')), 417),\n",
       " ((('scientifiques', 'NOUN'), 'cc', ('et', 'CCONJ')), 417),\n",
       " ((('sens', 'VERB'), 'ccomp', ('pourrions', 'VERB')), 417),\n",
       " ((('pourrions', 'VERB'), 'xcomp', ('emprunter', 'VERB')), 417),\n",
       " ((('pourrions', 'VERB'), 'obl', ('ça', 'PRON')), 417),\n",
       " ((('films', 'NOUN'), 'acl:relcl', ('vus', 'VERB')), 417),\n",
       " ((('médecins', 'NOUN'), 'case', ('de', 'ADP')), 417),\n",
       " ((('médecins', 'NOUN'), 'conj', ('scientifiques', 'NOUN')), 417),\n",
       " ((('ça', 'PRON'), 'case', ('entre', 'ADP')), 417),\n",
       " ((('sens', 'VERB'), 'punct', ('.', 'PUNCT')), 417),\n",
       " ((('emprunter', 'VERB'), 'obj', ('chemin', 'NOUN')), 417),\n",
       " ((('vus', 'VERB'), 'obj', ('que', 'PRON')), 417),\n",
       " ((('films', 'NOUN'), 'cc', ('et', 'CCONJ')), 417),\n",
       " ((('origine', 'NOUN'), 'det', (\"l'\", 'DET')), 417),\n",
       " ((('films', 'NOUN'), 'det', ('les', 'DET')), 417),\n",
       " ((('chemin', 'NOUN'), 'amod', ('autre', 'ADJ')), 417),\n",
       " ((('ça', 'PRON'), 'punct', (',', 'PUNCT')), 417)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse import (\n",
    "     DependencyGraph,\n",
    "     ProjectiveDependencyParser,\n",
    "     NonprojectiveDependencyParser,\n",
    " )\n",
    "from nltk import FreqDist\n",
    "\n",
    "root = \"../\"\n",
    "train = \"fr-ud-train.conllu3\"\n",
    "test = \"fr-ud-test.conllu3\"\n",
    "COLUMN_TYPES = ('ignore', \n",
    "                'words', \n",
    "                'ignore', \n",
    "                'pos', \n",
    "                'ignore', \n",
    "                'ignore', \n",
    "                'ignore', \n",
    "                'ignore', \n",
    "                'ignore', \n",
    "                'ignore')\n",
    "\n",
    "trainCorpus  = ConllCorpusReader(root=root, \n",
    "                                  fileids=train, \n",
    "                                  columntypes=COLUMN_TYPES, \n",
    "                                  encoding='utf8', \n",
    "                                  separator=\"\\t\", \n",
    "                                  tagset='universal')\n",
    "\n",
    "testCorpus  = ConllCorpusReader(root=root, \n",
    "                                  fileids=test, \n",
    "                                  columntypes=COLUMN_TYPES, \n",
    "                                  encoding='utf8', \n",
    "                                  separator=\"\\t\", \n",
    "                                  tagset='universal')\n",
    "\n",
    "#trainWords = trainCorpus.tagged_sents()\n",
    "testWords = testCorpus.tagged_sents()\n",
    "#print(trainWords)\n",
    "\n",
    "myfile = open(\"../fr-ud-test.conllu3\")\n",
    "conllfile = myfile.read()\n",
    "ff = conllfile.split('\\n\\n')\n",
    "dg = []\n",
    "for f in ff:\n",
    "    dg.append(DependencyGraph(ff[0], cell_separator='\\t', top_relation_label='root'))\n",
    "\n",
    "triplets = []\n",
    "for graph in dg:\n",
    "    for head, rel, dep in graph.triples():\n",
    "        triplets.append((head, rel, dep))\n",
    "fdist = FreqDist(triplets)\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
